import tkinter as tk
import heapq
from tkinter import filedialog, messagebox, ttk
import json
import os
import sys
import re
import threading
import tempfile
import shutil
import time
import logging
from datetime import datetime
from dateutil.parser import parse
import chardet
from multiprocessing import Pool, cpu_count
from functools import partial
import pytz
import hashlib

# –î–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ multiprocessing –Ω–∞ Windows
from multiprocessing import freeze_support

# –ö—ç—à –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç ‚Äî —É—Å–∫–æ—Ä–µ–Ω–∏–µ (–Ω–æ –¥–ª—è —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º)
DATE_PARSE_CACHE = {}

def cached_parse(dt_str):
    if dt_str not in DATE_PARSE_CACHE:
        try:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤—Ä–µ–º–µ–Ω–∏
            if ',' in dt_str and '.' not in dt_str:
                dt_str = dt_str.replace(',', '.')
            if dt_str.endswith("Z"):
                dt_str = dt_str.replace("Z", "+00:00")
            dt = parse(dt_str)
            if dt.tzinfo is None:
                dt = pytz.utc.localize(dt)
            # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥ –¥–æ 3 –∑–Ω–∞–∫–æ–≤ (–¥–ª—è .148 –∏–∑ .1482032)
            dt = dt.replace(microsecond=(dt.microsecond // 1000) * 1000)
            DATE_PARSE_CACHE[dt_str] = dt
        except Exception as e:
            logging.warning(f"Failed to cache parse {dt_str}: {e}")
            dt = datetime.now(pytz.utc)  # fallback –Ω–∞ —Ç–µ–∫—É—â–µ–µ UTC –≤—Ä–µ–º—è
            DATE_PARSE_CACHE[dt_str] = dt
    return DATE_PARSE_CACHE[dt_str]

def transform_log(original_json_str: str) -> str:
    """
    –ú–æ–¥—É–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ JSON-–ª–æ–≥–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç transform_generic_json –¥–ª—è ECS-—Ñ–æ—Ä–º–∞—Ç–∞.
    """
    try:
        entry = json.loads(original_json_str)
        if is_etalon_format(entry):
            return json.dumps(entry, ensure_ascii=False)
        transformed = transform_generic_json(entry, "")  # file_path –Ω–µ –Ω—É–∂–µ–Ω –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ
        return json.dumps(transformed, ensure_ascii=False)
    except json.JSONDecodeError as e:
        logging.warning(f"Invalid JSON: {e}")
        return json.dumps({"t": format_timestamp(datetime.now(pytz.utc)), "mt": original_json_str, "l": "Error"}, ensure_ascii=False)

def sanitize_filename(filename):
    """–ó–∞–º–µ–Ω—è–µ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è."""
    invalid_chars = '<>:"/\\|?*'
    for char in invalid_chars:
        filename = filename.replace(char, '_')
    return filename

def get_unique_filename(temp_dir, base_name):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö—ç—à–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–ª–ª–∏–∑–∏–π."""
    # –•—ç—à–∏—Ä—É–µ–º base_name –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
    hash_obj = hashlib.md5(base_name.encode())
    short_hash = hash_obj.hexdigest()[:8]
    unique_name = f"chunk_{short_hash}_{sanitize_filename(os.path.basename(base_name))}.tmp"
    return os.path.join(temp_dir, unique_name)

def extract_version_from_text(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤–µ—Ä—Å–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    if not text:
        return "unknown"
    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤–µ—Ä—Å–∏—é –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö
    match = re.search(r'\[(\d+\.\d+\.\d+(?:\.\d+)?)\]', text)
    if match:
        return match.group(1)
    # –ó–∞—Ç–µ–º –∏—â–µ–º –≤–µ—Ä—Å–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ "version":"..."
    match = re.search(r'"version"\s*:\s*"([^"]+)"', text)
    if match:
        return match.group(1)
    # –ó–∞—Ç–µ–º –∏—â–µ–º –≤–µ—Ä—Å–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ "module":"...Version=..."
    match = re.search(r'"module"\s*:\s*"([^"]*Version=([^",]+)[^"]*)"', text)
    if match:
        return match.group(2)
    # –ó–∞—Ç–µ–º –∏—â–µ–º –≤–µ—Ä—Å–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ "Version":"..."
    match = re.search(r'"Version"\s*:\s*"([^"]+)"', text)
    if match:
        return match.group(1)
    # –ó–∞—Ç–µ–º –∏—â–µ–º –≤–µ—Ä—Å–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ version= –∏–ª–∏ version:
    match = re.search(r'version[=:]\s*["\']?([^"\'>\s,]+)', text)
    if match:
        return match.group(1)
    # –ó–∞—Ç–µ–º –∏—â–µ–º –≤–µ—Ä—Å–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ elasticsearch-7.17.13.jar
    match = re.search(r'[-_]v?(\d+\.\d+\.\d+(?:\.\d+)?)', text)
    if match:
        return match.group(1)
    # –ó–∞—Ç–µ–º –∏—â–µ–º –≤–µ—Ä—Å–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ 7.17.13
    match = re.search(r'\b(\d+\.\d+\.\d+(?:\.\d+)?)\b', text)
    if match:
        return match.group(1)
    return "unknown"

def extract_service_name_from_path(file_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º—è —Å–µ—Ä–≤–∏—Å–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏–ª–∏ –ø—É—Ç–∏."""
    filename = os.path.basename(file_path).lower()
    candidates = [
        'elasticsearch', 'kibana', 'logstash', 'nginx', 'apache', 'redis', 'postgres',
        'mysql', 'mongo', 'rabbitmq', 'rabbit', 'kafka', 'zookeeper', 'traefik', 'haproxy',
        'grafana', 'prometheus', 'alertmanager', 'consul', 'vault', 'nomad',
        'beats', 'filebeat', 'metricbeat', 'auditbeat', 'journalbeat', 'winlogbeat',
        'fluentd', 'vector', 'telegraf', 'cadvisor', 'node_exporter', 'blackbox_exporter',
        'gateway', 'auth', 'payment', 'user', 'catalog', 'search', 'cache', 'queue',
        'worker', 'scheduler', 'report', 'backup', 'monitor', 'health', 'api', 'web'
    ]
    for candidate in candidates:
        if candidate in filename:
            return candidate.title()
    name = os.path.splitext(filename)[0]
    return sanitize_filename(name).title() or "Unknown"

def extract_tenant(entry):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º—è —Ç–µ–Ω–∞–Ω—Ç–∞ –∏–∑ –∑–∞–ø–∏—Å–∏."""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º tn –Ω–∞–ø—Ä—è–º—É—é
    if "tn" in entry:
        return entry["tn"]
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º host.name
    if "host" in entry and isinstance(entry["host"], dict) and "name" in entry["host"]:
        return entry["host"]["name"]
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º cluster.name –∏ node.name
    cluster_name = entry.get("cluster.name")
    node_name = entry.get("node.name")
    if cluster_name and node_name:
        return f"{cluster_name}-{node_name}"
    if node_name:
        return node_name
    if cluster_name:
        return cluster_name
    return None

def extract_logger(entry):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º—è –ª–æ–≥–≥–µ—Ä–∞ –∏–∑ –∑–∞–ø–∏—Å–∏."""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º lg –Ω–∞–ø—Ä—è–º—É—é
    if "lg" in entry:
        return entry["lg"]
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º logger
    if "logger" in entry:
        if isinstance(entry["logger"], str):
            return entry["logger"]
        elif isinstance(entry["logger"], dict) and "name" in entry["logger"]:
            return entry["logger"]["name"]
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º component
    if "component" in entry:
        return entry["component"]
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º service.name
    if "service" in entry and isinstance(entry["service"], dict) and "name" in entry["service"]:
        return entry["service"]["name"]
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º app_id
    if "app_id" in entry:
        return entry["app_id"]
    return None

def format_timestamp(dt):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç—É –≤ —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD HH:MM:SS.mmm+HH:MM."""
    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ dt - datetime —Å —Ç–∞–π–º–∑–æ–Ω–æ–π
    if dt.tzinfo is None:
        dt = pytz.utc.localize(dt)
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ YYYY-MM-DD HH:MM:SS.mmm+HHMM
    t_formatted = dt.strftime("%Y-%m-%d %H:%M:%S.%f")[:-3] + dt.strftime("%z")
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–≤–æ–µ—Ç–æ—á–∏–µ –≤ —Ç–∞–π–º–∑–æ–Ω—É: +HHMM -> +HH:MM
    if len(t_formatted) == 28: # 23 (–±–∞–∑–∞) + 5 (HHMM)
        t_formatted = t_formatted[:-2] + ":" + t_formatted[-2:]
    return t_formatted

def is_etalon_format(entry):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–∞–ø–∏—Å—å —ç—Ç–∞–ª–æ–Ω–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É.
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–æ–ª—å–∫–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –∏ —Ñ–æ—Ä–º–∞—Ç –≤—Ä–µ–º–µ–Ω–∏ 't'.
    """
    if not isinstance(entry, dict):
        return False

    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è —ç—Ç–∞–ª–æ–Ω–∞
    required_keys = {'t', 'pid', 'l', 'lg', 'tn', 'v'}
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
    if not required_keys.issubset(entry.keys()):
        return False

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ 't' - —Å—Ç—Ä–æ–∫–∞ —Å –ø–æ—Ö–æ–∂–∏–º —Ñ–æ—Ä–º–∞—Ç–æ–º –≤—Ä–µ–º–µ–Ω–∏
    t_val = entry.get('t')
    if not isinstance(t_val, str) or not re.match(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}[+-]\d{2}:\d{2}$', t_val):
        return False

    # –î—Ä—É–≥–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å, –Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ö–≤–∞—Ç–∏—Ç –∏ —ç—Ç–∏—Ö
    return True

def parse_log_line(line, file_path):
    line = line.strip()
    if not line:
        return None

    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ JSON ---
    if line.startswith('{'):
        try:
            entry = json.loads(line)
            # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ---
            if is_etalon_format(entry):
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–ø–∏—é –∏–¥–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –ë–ï–ó –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Ä–µ–º–µ–Ω–∏
                # (–ø–æ—Å–∫–æ–ª—å–∫—É regex —É–∂–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç 't')
                return dict(entry)
            # --- –ö–æ–Ω–µ—Ü –ø—Ä–æ–≤–µ—Ä–∫–∏ ---
            # –ï—Å–ª–∏ –Ω–µ —ç—Ç–∞–ª–æ–Ω, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
            return transform_generic_json(entry, file_path)
        except json.JSONDecodeError:
            # –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON ‚Äî –¥–∞–ª—å—à–µ –ø—Ä–æ–±—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
            pass

    # --- –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã ---
    procrun_pattern = re.compile(r'^\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\] \[info\]', re.IGNORECASE)
    elasticsearch_pattern = re.compile(
        r'.*\[(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2},\d{3})\]\[([A-Z]+)\]\[.*?\]',
        re.IGNORECASE
    )
    linux_syslog_pattern = re.compile(
        r'^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6}\+\d{2}:\d{2} [a-zA-Z0-9_-]+ \w+\[\d+\]:'
    )

    try:
        if procrun_pattern.match(line):
            return transform_procrun_log(line, file_path)
        if elasticsearch_pattern.match(line):
            return transform_elasticsearch_log(line, file_path)
        if linux_syslog_pattern.match(line):
            return transform_linux_syslog_to_etalon(line, file_path)
    except Exception as e:
        logging.warning(f"Failed to parse line in {file_path}: {line[:200]}... Error: {e}")

    return create_minimal_entry(line, file_path)

def transform_generic_json(entry, file_path):
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π JSON-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä.
    –ù–ï –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç - —ç—Ç–æ –¥–µ–ª–∞–µ—Ç parse_log_line.
    –¢–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç. –£–ª—É—á—à–µ–Ω–æ: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ID –∏ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –ø–æ–ª–µ–π –≤ args.
    """
    if not isinstance(entry, dict):
        return create_minimal_entry(json.dumps(entry), file_path)

    # --- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ-—ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π ---
    standard_out = {"t", "pid", "tr", "l", "lg", "mt", "tn", "v", "args", "ex", "trace_id", "transaction_id"}
    original = entry
    transformed = {}

    # 1. –í—Ä–µ–º—è
    dt_candidates = ["t", "@timestamp", "timestamp", "date", "time"]
    dt_str = None
    for k in dt_candidates:
        if k in original and original.get(k):
            dt_str = original.get(k)
            break
    if dt_str:
        try:
            s = str(dt_str)
            transformed["t"] = format_timestamp(cached_parse(s))
        except Exception as e:
            logging.warning(f"Failed to parse timestamp {dt_str}: {e}")
            transformed["t"] = format_timestamp(datetime.now(pytz.utc))
    else:
        transformed["t"] = format_timestamp(datetime.now(pytz.utc))

    # 2. –£—Ä–æ–≤–µ–Ω—å
    try:
        level = None
        if isinstance(original.get("log"), dict):
            level = original["log"].get("level")
        if not level and "level" in original:
            level = original.get("level")
        if not level and "log.level" in original:
            level = original.get("log.level")
        if not level:
            s = json.dumps(original).lower()
            if '"level":"error"' in s or '[error]' in s:
                level = "Error"
            elif '"level":"warn"' in s or '[warn]' in s or '[warning]' in s:
                level = "Warn"
            elif '"level":"debug"' in s or '[debug]' in s:
                level = "Debug"
            elif '"level":"fatal"' in s or '[fatal]' in s:
                level = "Fatal"
            elif '"level":"info"' in s or '[info]' in s:
                level = "Information"
            else:
                level = "Information"
        full_level = str(level)
        short_level = full_level if full_level != "Information" else "Info"
        transformed["l"] = short_level
    except Exception as e:
        logging.warning(f"Failed to extract level: {e}")
        transformed["l"] = "Info"
        full_level = "Information"

    # 3. PID
    try:
        if "pid" in original and original["pid"]:
            transformed["pid"] = str(original["pid"])
        else:
            pid = None
            if isinstance(original.get("process"), dict):
                pid = original["process"].get("pid") or original["process"].get("id")
            if not pid:
                pid = original.get("process.id") or original.get("process.pid")
            transformed["pid"] = str(pid) if pid is not None else "1"
    except Exception as e:
        logging.warning(f"Failed to extract PID: {e}")
        transformed["pid"] = "1"

    # 4. Trace ID (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
    try:
        if "trace" in original and isinstance(original["trace"], dict) and "id" in original["trace"]:
            transformed["trace_id"] = original["trace"]["id"]
        elif "tr" in original and original["tr"]:
            transformed["trace_id"] = original["tr"]
    except Exception as e:
        logging.warning(f"Failed to extract trace_id: {e}")

    # 5. Transaction ID (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
    try:
        if "transaction" in original and isinstance(original["transaction"], dict) and "id" in original["transaction"]:
            transformed["transaction_id"] = original["transaction"]["id"]
    except Exception as e:
        logging.warning(f"Failed to extract transaction_id: {e}")

    # 6. Logger
    try:
        if "lg" in original and original["lg"]:
            transformed["lg"] = original["lg"]
        else:
            logger = extract_logger(original)
            transformed["lg"] = logger if logger else extract_service_name_from_path(file_path)
    except Exception as e:
        logging.warning(f"Failed to extract logger: {e}")
        transformed["lg"] = extract_service_name_from_path(file_path)

    # 7. Message
    try:
        if "mt" in original and original["mt"]:
            transformed["mt"] = original["mt"]
        else:
            transformed["mt"] = original.get("message") or original.get("msg", "")
    except Exception as e:
        logging.warning(f"Failed to extract message: {e}")
        transformed["mt"] = ""

    # 8. Tenant
    try:
        if "tn" in original and original["tn"]:
            transformed["tn"] = original["tn"]
        else:
            tenant = extract_tenant(original)
            transformed["tn"] = tenant if tenant else extract_service_name_from_path(file_path)
    except Exception as e:
        logging.warning(f"Failed to extract tenant: {e}")
        transformed["tn"] = extract_service_name_from_path(file_path)

    # 9. Version
    try:
        if "v" in original and original["v"]:
            transformed["v"] = original["v"]
        else:
            if isinstance(original.get("service"), dict) and original["service"].get("version"):
                transformed["v"] = original["service"]["version"]
            else:
                msg = transformed["mt"] if "mt" in transformed else str(original)
                transformed["v"] = extract_version_from_text(msg)
    except Exception as e:
        logging.warning(f"Failed to extract version: {e}")
        transformed["v"] = "unknown"

    # 10. Span
    try:
        if "span" in original:
            transformed["span"] = original["span"]
    except Exception as e:
        logging.warning(f"Failed to extract span: {e}")

    # 11. Errors
    try:
        error_fields = ["exception", "error", "err", "stacktrace", "stack_trace"]
        ex_dict = {}
        for fld in error_fields:
            if fld in original:
                ex_dict[fld] = original[fld]
        if ex_dict:
            transformed["ex"] = ex_dict
    except Exception as e:
        logging.warning(f"Failed to extract errors: {e}")

    # 12. Args - —Å–æ–±–∏—Ä–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø–æ–ª—è + –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ
    args = {}
    try:
        # –û—Å—Ç–∞–≤—à–∏–µ—Å—è –ø–æ–ª—è (–∏—Å–∫–ª—é—á–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ)
        for k, v in original.items():
            if k in standard_out or k in ["log", "process", "service", "host", "trace", "transaction", "logger", "component", "app_id", "cluster.name", "node.name"]:
                continue
            args[k] = v

        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –ø–æ–ª–µ–π –≤ args
        # Trace (–ø–æ–ª–Ω–æ—Å—Ç—å—é, id —É–∂–µ –≤—ã–Ω–µ—Å–µ–Ω)
        if "trace" in original:
            args["trace"] = original["trace"]

        # Transaction (–ø–æ–ª–Ω–æ—Å—Ç—å—é, id —É–∂–µ –≤—ã–Ω–µ—Å–µ–Ω)
        if "transaction" in original:
            args["transaction"] = original["transaction"]

        # Host.user
        if "host" in original and isinstance(original["host"], dict) and "user" in original["host"] and isinstance(original["host"]["user"], dict):
            if "host" not in args:
                args["host"] = {}
            args["host"]["user"] = original["host"]["user"]

        # Log (—Å logger, original, level)
        if "log" in original:
            log_data = original["log"].copy()
            log_data["level"] = full_level  # –ü–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è level
            args["log"] = log_data

        # Process (—Å thread.id, name, executable; pid —É–∂–µ –≤—ã–Ω–µ—Å–µ–Ω)
        if "process" in original:
            process = original["process"].copy()
            process.pop("pid", None)  # –ù–µ –¥—É–±–ª–∏—Ä—É–µ–º
            args["process"] = process

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ args
        args = remove_time_duplicates_from_args(args, transformed.get("t"))

        if args:
            transformed["args"] = args
    except Exception as e:
        logging.warning(f"Failed to build args: {e}")

    return transformed

def transform_ecs(entry):
    transformed = {}

    # --- 1. –í—Ä–µ–º—è ---
    dt_str = entry.pop("@timestamp", None)
    if dt_str:
        try:
            dt = cached_parse(dt_str)
            transformed["t"] = format_timestamp(dt)
        except Exception:
            transformed["t"] = format_timestamp(datetime.now(pytz.utc))
    else:
        transformed["t"] = format_timestamp(datetime.now(pytz.utc))

    # --- 2. –£—Ä–æ–≤–µ–Ω—å ---
    log_info = entry.pop("log", {})
    level = log_info.get("level", "information").title()
    level = (
        level.replace("Information", "Info")
             .replace("Warning", "Warn")
             .replace("Critical", "Fatal")
    )
    transformed["l"] = level

    # --- 3. –°–µ—Ä–≤–∏—Å –∏ –ª–æ–≥–≥–µ—Ä ---
    service = entry.pop("service", {})
    service_name = service.get("name", "UnknownService")
    transformed["lg"] = log_info.get("logger", service_name)

    # --- 4. –ü—Ä–æ—Ü–µ—Å—Å ---
    process = entry.pop("process", {})
    pid = process.get("pid", "1")
    transformed["pid"] = str(pid)

    # --- 5. –°–æ–æ–±—â–µ–Ω–∏–µ ---
    message = entry.pop("message", "")
    transformed["mt"] = message

    # --- 6. –ê—Ä–≥—É–º–µ–Ω—Ç—ã (–æ—Å—Ç–∞–≤—à–µ–µ—Å—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ) ---
    transformed["args"] = {}
    for key, value in entry.items():
        if key not in ["labels", "ecs", "host"]:
            transformed["args"][key] = value

    if "host" in entry:
        transformed["args"]["host"] = entry["host"]

    # --- 7. Host –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ª–æ–≥ ---
    if "original" in log_info:
        transformed["args"]["original_log_info"] = log_info["original"]

    # --- 8. Transaction name + –≤–µ—Ä—Å–∏—è ---
    transformed["tn"] = service_name
    transformed["v"] = extract_version_from_text(message)

    return transformed

def transform_elasticsearch_log(entry):
    transformed = {}
    dt_str = entry.get("timestamp", "").replace(',', '.')
    try:
        dt = cached_parse(dt_str)
        transformed["t"] = format_timestamp(dt)
    except Exception:
        transformed["t"] = format_timestamp(datetime.now(pytz.utc))
    transformed["pid"] = str(entry.get("process.id", "1"))
    level = entry.get("level", "INFO")
    transformed["l"] = level.title().replace("Critical", "Fatal")
    transformed["lg"] = entry.get("component", "Elasticsearch")
    transformed["mt"] = entry.get("message", "")
    transformed["args"] = {}
    excluded_keys = {"timestamp", "level", "component", "message", "type", "cluster.name", "node.name", "process.id"}
    for key, value in entry.items():
        if key not in excluded_keys:
            transformed["args"][key] = value
    transformed["tn"] = entry.get("node.name", "Elasticsearch")
    transformed["v"] = extract_version_from_text(transformed["mt"])
    return transformed

def transform_procrun_log(line, file_path):
    transformed = {}
    parts = re.split(r'\[(.*?)\]', line.strip())
    try:
        dt = cached_parse(parts[1].strip())
        transformed["t"] = format_timestamp(dt)
    except Exception:
        transformed["t"] = format_timestamp(datetime.now(pytz.utc))
    level = parts[3].strip()
    transformed["l"] = "Info" if level.lower() == "info" else level.title().replace("Critical", "Fatal")
    service_name = extract_service_name_from_path(file_path)
    transformed["lg"] = "Commons Daemon"
    transformed["pid"] = parts[5].strip() if len(parts) > 5 else "1"
    rest = " ".join(parts[6:]).strip()
    transformed["mt"] = rest
    transformed["args"] = {}
    transformed["tn"] = service_name
    transformed["v"] = extract_version_from_text(rest)
    return transformed

def transform_linux_syslog_to_etalon(line, file_path):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç syslog –≤ —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    match = re.search(r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6}\+\d{2}:\d{2}) ([a-zA-Z0-9_-]+) (\w+)\[(\d+)\]: (.*)', line)
    if not match:
        return create_minimal_entry(line, file_path)
    dt_str, host, service_name, pid, message = match.groups()
    # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è
    try:
        dt = cached_parse(dt_str)
        t_formatted = format_timestamp(dt)
    except Exception:
        t_formatted = format_timestamp(datetime.now(pytz.utc))
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
    lg = service_name
    if "DocumentAssemblerService" in message:
        lg = "DocumentAssemblerService"
    elif "TextExtractorService" in message:
        lg = "TextExtractorService"
    else:
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–µ—Ä–≤–∏—Å –≤ —Ç–µ–∫—Å—Ç–µ
        services = ["DocumentAssemblerService", "TextExtractorService", "RabbitMqSubscriber", "GenericService"]
        for svc in services:
            if svc in message:
                lg = svc
                break
    # –°–æ–∑–¥–∞–µ–º span –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
    span_name = "SystemLog"
    if "AMQP connection" in message:
        span_name = "AMQP connection"
    elif "closing" in message:
        span_name = "Closing connection"
    # –£–ø—Ä–æ—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —É–¥–∞–ª—è–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    clean_message = message
    clean_message = re.sub(r'<[^>]+>', '', clean_message)  # —É–¥–∞–ª—è–µ–º <0.123.0>
    clean_message = re.sub(r'vhost:.*?,', '', clean_message)
    clean_message = re.sub(r'\s+', ' ', clean_message).strip()
    return {
        "t": t_formatted,
        "pid": pid,
        "l": "Info",
        "lg": lg,
        "span": {
            "status": "Info",
            "name": span_name,
            "messageType": "SystemLog",
            "message": clean_message
        },
        "tn": lg,
        # "v" –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º ‚Äî –≤ syslog –æ–±—ã—á–Ω–æ –Ω–µ—Ç –≤–µ—Ä—Å–∏–∏
    }

def create_minimal_entry(line, file_path):
    """–°–æ–∑–¥–∞—ë—Ç –∑–∞–ø–∏—Å—å, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç—Ä–æ–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ –±—ã–ª–∞ JSON –∏–ª–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞. –ò—â–µ—Ç –∏—Å—Ç–∏–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Å–æ–±—ã—Ç–∏—è –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏. –£–±–∏—Ä–∞–µ—Ç `_raw_line` –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ."""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –≤–∞–ª–∏–¥–Ω—ã–º JSON
    stripped_line = line.strip()
    is_json = False
    original_json_obj = None
    if stripped_line.startswith('{'):
        try:
            original_json_obj = json.loads(stripped_line)
            is_json = True
        except json.JSONDecodeError:
            pass # –≠—Ç–æ –Ω–µ –≤–∞–ª–∏–¥–Ω—ã–π JSON

    transformed = {}

    raw_line = line.strip()
    # –®–∞–±–ª–æ–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –°–û–ë–´–¢–ò–Ø (–Ω–µ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞)
    event_time_patterns = [
        r'(\d{2})\.(\d{2})\.(\d{4})\s+(\d{1,2}):(\d{2}):(\d{2})',  # DD.MM.YYYY H:M:S
        r'(\d{4})-(\d{2})-(\d{2})\s+(\d{2}):(\d{2}):(\d{2})(?:\.(\d{3,6}))?',  # YYYY-MM-DD HH:MM:SS[.mmm]
    ]
    event_time = None
    for pattern in event_time_patterns:
        match = re.search(pattern, raw_line)
        if match:
            try:
                if pattern.startswith(r'(\d{2})\.'):  # DD.MM.YYYY
                    day, month, year, hour, minute, second = match.groups()[:6]
                    dt = datetime(int(year), int(month), int(day), int(hour), int(minute), int(second))
                else:  # YYYY-MM-DD
                    year, month, day, hour, minute, second, ms = match.groups()
                    dt = datetime(int(year), int(month), int(day), int(hour), int(minute), int(second))
                    if ms:
                        microsecond = int(ms.ljust(6, '0')[:6])
                        dt = dt.replace(microsecond=microsecond)
                # –õ–æ–∫–∞–ª–∏–∑—É–µ–º –≤ UTC, –µ—Å–ª–∏ –Ω–µ—Ç —Ç–∞–π–º–∑–æ–Ω—ã
                if dt.tzinfo is None:
                    dt = pytz.utc.localize(dt)
                event_time = dt
                break
            except Exception as e:
                logging.warning(f"Failed to parse event time with pattern {pattern}: {e}")
                continue

    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –≤—Ä–µ–º—è —Å–æ–±—ã—Ç–∏—è ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    if event_time:
        t_formatted = format_timestamp(event_time)
        transformed["t"] = t_formatted
    else:
        # –ò–Ω–∞—á–µ ‚Äî –±–µ—Ä—ë–º –≤—Ä–µ–º—è –∏–∑ –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫–∏ (fallback)
        start_time_match = re.search(r'^\s*(\d{4}-\d{2}-\d{2}[T\s]\d{2}:\d{2}:\d{2}(?:[.,]\d{3,})?)', raw_line)
        if start_time_match:
            dt_str = start_time_match.group(1).replace(',', '.')
            try:
                dt = cached_parse(dt_str)
                t_formatted = format_timestamp(dt)
                transformed["t"] = t_formatted
            except Exception:
                transformed["t"] = format_timestamp(datetime.now(pytz.utc))
        else:
            transformed["t"] = format_timestamp(datetime.now(pytz.utc))

    # ‚û§‚û§‚û§ –í–°–Å –û–°–¢–ê–õ–¨–ù–û–ï ‚Äî –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô ‚Äî –ù–ò–ß–ï–ì–û –ù–ï –£–î–ê–õ–Ø–ï–ú
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —É—Ä–æ–≤–µ–Ω—å
    level = "Info"
    lower_line = raw_line.lower()
    if re.search(r'\b(error|err|–Ω–µ —É–¥–∞–ª–æ—Å—å|–∏—Å–∫–ª—é—á–µ–Ω–∏–µ)\b', lower_line):
        level = "Error"
    elif re.search(r'\b(warn|warning)\b', lower_line):
        level = "Warn"
    elif re.search(r'\b(debug)\b', lower_line):
        level = "Debug"
    elif re.search(r'\b(fatal|crit|critical)\b', lower_line):
        level = "Fatal"
    elif re.search(r'\b(info|information)\b', lower_line):
        level = "Info"
    transformed["l"] = level

    # –ò–∑–≤–ª–µ–∫–∞–µ–º PID
    pid = "1"
    pid_match = re.search(r'[<\(]([^>)]+)[>\)]', raw_line)
    if pid_match:
        pid = pid_match.group(1)
    else:
        parts = raw_line.split()
        if len(parts) >= 2:
            last_part = parts[-1]
            if re.match(r'^\d+\+\d+$', last_part) or last_part.isdigit():
                pid = last_part
    transformed["pid"] = pid

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Ä—Å–∏—é
    ver_match = re.search(r'(\d+\.\d+\.\d+(?:\.\d+)?)', raw_line)
    transformed["v"] = ver_match.group(1) if ver_match else "unknown"

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ª–æ–≥–≥–µ—Ä
    logger = extract_service_name_from_path(file_path)
    if "|" in raw_line:
        before_pipe = raw_line.split("|", 1)[0].strip()
        parts = before_pipe.split()
        if len(parts) >= 2:
            logger = parts[-1]
    transformed["lg"] = logger

    # Transaction name
    transformed["tn"] = extract_service_name_from_path(file_path)

    # –ü–∞—Ä—Å–∏–Ω–≥ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ª–æ–≥–æ–≤
    un_match = re.search(r'UserName:\s*(.+?)(?:\n|$)', raw_line, re.IGNORECASE)
    if un_match:
        transformed["un"] = un_match.group(1).strip()

    tr_match = re.search(r'Trace:\s*(.+?)(?:\n|$)', raw_line, re.IGNORECASE)
    if tr_match:
        transformed["tr"] = tr_match.group(1).strip()

    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï ---
    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –±—ã–ª–∞ JSON, –Ω–æ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞, –∏ –Ω–µ –±—ã–ª–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ transform_generic_json (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—à–∏–±–∫–∞),
    # —Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë –∫–∞–∫ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –≤ args, –Ω–æ –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º _raw_line.
    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –±—ã–ª–∞ –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–º, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ span.message.
    if is_json and original_json_obj:
         # –°—á–∏—Ç–∞–µ–º, —á—Ç–æ JSON-—Å—Ç—Ä–æ–∫–∞ –±—ã–ª–∞ "–æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞" –∫–∞–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
         # –ü–æ–º–µ—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π JSON-–æ–±—ä–µ–∫—Ç –≤ args –ø–æ–¥ –∫–ª—é—á–æ–º _original_json, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π
         # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –Ω–æ –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –∏—Ö –≤ _raw_line
         # –û–¥–Ω–∞–∫–æ, —á—Ç–æ–±—ã –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä –µ—â—ë –±–æ–ª—å—à–µ, –∏ –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è —É–∂–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã,
         # –º–æ–∂–Ω–æ –Ω–µ –¥–æ–±–∞–≤–ª—è—Ç—å _original_json. –û—Å—Ç–∞–≤–∏–º –Ω–∞ —É—Å–º–æ—Ç—Ä–µ–Ω–∏–µ.
         # –î–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞: –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º _raw_line –∏ _original_json –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ.
         # –°–æ–æ–±—â–µ–Ω–∏–µ –º–æ–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –∏–∑ JSON, –µ—Å–ª–∏ –æ–Ω–æ –±—ã–ª–æ.
         # –ù–æ –≤ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∑–∞–ø–∏—Å–∏ –æ–Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ —è–≤–Ω–æ.
         # –ü—Ä–æ—Å—Ç–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º _raw_line.
         pass # –ü—Ä–æ—Å—Ç–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º _raw_line
    else:
        # –≠—Ç–æ –±—ã–ª–∞ —Ç–µ–∫—Å—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞, –∫–æ—Ç–æ—Ä—É—é –º—ã –Ω–µ —Å–º–æ–≥–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∫–∞–∫ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç.
        # –†–∞–Ω—å—à–µ –¥–æ–±–∞–≤–ª—è–ª–∏ _raw_line, —Ç–µ–ø–µ—Ä—å –¥–æ–±–∞–≤–∏–º –≤ span.message.
        clean_message = re.sub(r'<[^>]+>', '', raw_line).strip()  # –¢–æ–ª—å–∫–æ —É–¥–∞–ª—è–µ–º —Ç–µ–≥–∏ –∏ trim –∫—Ä–∞—ë–≤, –ë–ï–ó —Å–∂–∞—Ç–∏—è –ø—Ä–æ–±–µ–ª–æ–≤
        transformed["span"] = {
            "status": "Info",
            "name": "RawLogLine",
            "messageType": "Text",
            "message": clean_message
        }

    return transformed

def clean_nested_duplicates(nested_dict, transformed_entry):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ –≤–ª–æ–∂–µ–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –Ω–∞ –æ—Å–Ω–æ–≤–µ transformed_entry."""
    if not isinstance(nested_dict, dict):
        return nested_dict

    cleaned = {}
    normalized_time = transformed_entry.get("t")

    for k, v in nested_dict.items():
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—É—â–∏–π –∫–ª—é—á –¥—É–±–ª–∏–∫–∞—Ç–æ–º –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è
        if k in {"@timestamp", "timestamp", "time", "date"}:
            if normalized_time:
                try:
                    sval = str(v)
                    if sval.endswith("Z"):
                        sval = sval.replace("Z", "+00:00")
                    dt2 = cached_parse(sval)
                    if format_timestamp(dt2) == normalized_time:
                        continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç –≤—Ä–µ–º–µ–Ω–∏
                except Exception:
                    pass # –ï—Å–ª–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–æ—Å—å, –≤—Å—ë —Ä–∞–≤–Ω–æ –¥–æ–±–∞–≤–∏–º
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—É—â–∏–π –∫–ª—é—á –¥—É–±–ª–∏–∫–∞—Ç–æ–º —É—Ä–æ–≤–Ω—è l, pid, mt, tn, v
        elif k == "level" and transformed_entry.get("l") and str(v).title() == transformed_entry["l"]:
            continue
        elif k == "pid" and transformed_entry.get("pid") and str(v) == transformed_entry["pid"]:
            continue
        elif k == "message" and transformed_entry.get("mt") and v == transformed_entry["mt"]:
            continue
        elif k == "name" and transformed_entry.get("tn") and v == transformed_entry["tn"]:
            continue
        elif k == "version" and transformed_entry.get("v") and v == transformed_entry["v"]:
            continue
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏
        elif isinstance(v, dict):
            cleaned_v = clean_nested_duplicates(v, transformed_entry)
            if cleaned_v: # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–∏
                cleaned[k] = cleaned_v
        # –î–ª—è –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤, –ø—Ä–æ–≤–µ—Ä–∏–º —ç–ª–µ–º–µ–Ω—Ç—ã, –µ—Å–ª–∏ –æ–Ω–∏ —Å–ª–æ–≤–∞—Ä–∏
        elif isinstance(v, list):
            cleaned_list = []
            for item in v:
                if isinstance(item, dict):
                     cleaned_item = clean_nested_duplicates(item, transformed_entry)
                     if cleaned_item:
                         cleaned_list.append(cleaned_item)
                else:
                     cleaned_list.append(item)
            if cleaned_list: # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏
                cleaned[k] = cleaned_list
        else:
            cleaned[k] = v

    return cleaned

def remove_time_duplicates_from_args(args_dict, normalized_time_str):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è args."""
    if not normalized_time_str or not isinstance(args_dict, dict):
        return args_dict

    def _clean_time_recursive(d):
        if isinstance(d, dict):
            new_d = {}
            for k, v in d.items():
                if k in {"@timestamp", "timestamp", "time", "date"}:
                    if isinstance(v, str):
                        try:
                            sval = v
                            if sval.endswith("Z"):
                                sval = sval.replace("Z", "+00:00")
                            dt2 = cached_parse(sval)
                            if format_timestamp(dt2) == normalized_time_str:
                                continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç
                        except Exception:
                            pass # –ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ, –¥–æ–±–∞–≤–∏–º
                elif isinstance(v, dict):
                    new_d[k] = _clean_time_recursive(v)
                elif isinstance(v, list):
                    new_d[k] = [_clean_time_recursive(item) if isinstance(item, dict) else item for item in v]
                else:
                    new_d[k] = v
            return new_d
        return d

    return _clean_time_recursive(args_dict)

def process_file_and_sort_chunk(args):
    i, file_path, temp_dir = args
    sorted_entries = []
    detected_encoding = None
    try:
        # --- 1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ ---
        with open(file_path, 'rb') as f:
            raw_data = f.read(8192)  # –ß–∏—Ç–∞–µ–º –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            result = chardet.detect(raw_data)
            chardet_encoding = result['encoding']
            confidence = result['confidence']
            logging.info(f"Chardet: {chardet_encoding} (conf: {confidence:.2f}) for {file_path}")

        # –ö–∞–Ω–¥–∏–¥–∞—Ç—ã: —Å–Ω–∞—á–∞–ª–∞ chardet, –ø–æ—Ç–æ–º cp1251, utf-8-sig, utf-8
        encodings_to_try = []
        if chardet_encoding and confidence > 0.6:
            encodings_to_try.append(chardet_encoding)
        encodings_to_try.extend(['cp1251', 'utf-8-sig', 'utf-8'])

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        seen = set()
        encodings_to_try = [e for e in encodings_to_try if e and not (e in seen or seen.add(e))]

        content_lines = None
        for enc in encodings_to_try:
            try:
                with open(file_path, 'r', encoding=enc, errors='strict') as f:
                    content_lines = f.readlines()
                detected_encoding = enc
                logging.info(f"Successfully read {file_path} with encoding: {enc}")
                break
            except (UnicodeDecodeError, LookupError) as e:
                logging.debug(f"Failed to read {file_path} with {enc}: {e}")
                continue

        if content_lines is None:
            # –ü–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å: —á–∏—Ç–∞–µ–º —Å errors='replace'
            logging.warning(f"Fallback to cp1251 with errors='replace' for {file_path}")
            with open(file_path, 'r', encoding='cp1251', errors='replace') as f:
                content_lines = f.readlines()
            detected_encoding = 'cp1251 (fallback)'

        # --- 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫ ---
        for line in content_lines:
            entry = parse_log_line(line, file_path)
            if entry:
                sorted_entries.append(entry)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        sorted_entries.sort(key=lambda x: x.get('t', ''))

        # --- 3. –ó–∞–ø–∏—Å—å –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ UTF-8 ---
        temp_file = get_unique_filename(temp_dir, file_path)
        with open(temp_file, 'w', encoding='utf-8', errors='replace') as tf:
            for entry in sorted_entries:
                json_line = json.dumps(entry, ensure_ascii=False, indent=None)
                tf.write(json_line + '\n')

        return temp_file

    except Exception as e:
        logging.error(f"Critical error processing {file_path}: {e}", exc_info=True)
        return None

def resource_path(relative_path):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —Ä–µ—Å—É—Ä—Å–∞–º, —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –≤ PyInstaller, –∏ –≤ –æ–±—ã—á–Ω–æ–º Python"""
    try:
        # PyInstaller —Å–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É _MEIPASS
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath(".")
    return os.path.join(base_path, relative_path)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ç—ë–º–Ω–æ–π —Ç–µ–º—ã title bar –Ω–∞ Windows (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
def setup_windows_dark_titlebar(root):
    if os.name == 'nt':  # Windows
        try:
            import ctypes
            from ctypes import wintypes
            # –ü–æ–ª—É—á–∞–µ–º handle –æ–∫–Ω–∞
            hwnd = ctypes.windll.user32.GetParent(root.winfo_id())
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º DWMWA_USE_IMMERSIVE_DARK_MODE = 20 (Windows 10+)
            ctypes.windll.dwmapi.DwmSetWindowAttribute(hwnd, 20, ctypes.byref(ctypes.c_int(1)), ctypes.sizeof(ctypes.c_int))
        except Exception:
            pass  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º

class LogMergerApp:
    def __init__(self, root):
        self.root = root
        self.root.title("logmrgr v031.6")
        icon_path = resource_path("icon/icon.ico")
        self.root.iconbitmap(icon_path)
        self.root.geometry("250x350")
        self.root.resizable(False, False)
        self.root.configure(bg="#2E2E2E")
        # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º —Ç—ë–º–Ω—É—é —Ç–µ–º—É –¥–ª—è title bar –Ω–∞ Windows
        setup_windows_dark_titlebar(root)
        self.loaded_files = []
        self.temp_dir = tempfile.mkdtemp()
        self.temp_files = []
        self.after_id = None
        self.progress_value = 0
        self.progress_lock = threading.Lock()
        self.total_lines = 0
        self.current_line = 0
        self.last_update_time = 0
        self.style = ttk.Style()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º 'clam' –¥–ª—è –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–∏, –Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥ —Ç—ë–º–Ω—É—é —Ç–µ–º—É
        self.style.theme_use('clam')
        # –¢—ë–º–Ω–∞—è —Ç–µ–º–∞ –¥–ª—è –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        self.style.configure('TFrame', background='#2E2E2E')
        self.style.configure('TLabel', background='#2E2E2E', foreground='white', font=('Arial', 9))
        self.style.configure('Fixed.TButton', background='#4A4A4A', foreground='white', bordercolor='#555555', padding=5, focuscolor='none')
        self.style.map('Fixed.TButton', background=[('active', '#006400'), ('pressed', '#004d00')], foreground=[('active', 'white')])
        # —Å—Ç–∏–ª—å –ø–æ–¥—Å–≤–µ—á–µ–Ω–Ω–æ–π –∫–Ω–æ–ø–∫–∏
        self.style.configure('Highlight.TButton',
                             background='#228B22', foreground='white',
                             bordercolor='#00FF00', padding=5)
        self.style.map('Highlight.TButton',
                       background=[('active', '#32CD32')],
                       foreground=[('active', 'white')])
        # –¢—ë–º–Ω–∞—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        self.style.configure(
            "Green.Horizontal.TProgressbar",
            troughcolor="#2E2E2E",   # —Ñ–æ–Ω –∫–∞–Ω–∞–≤–∫–∏ (—Ç—ë–º–Ω—ã–π —Å–µ—Ä—ã–π)
            background="#00FF00",   # –æ—Å–Ω–æ–≤–Ω–æ–π –∑–µ–ª—ë–Ω—ã–π
            bordercolor="#2E2E2E",
            lightcolor="#33FF33",   # –ø–æ–¥—Å–≤–µ—Ç–∫–∞ —Å–≤–µ—Ä—Ö—É
            darkcolor="#009900"     # –∑–∞—Ç–µ–º–Ω–µ–Ω–∏–µ —Å–Ω–∏–∑—É
        )
        self.style.configure('TNotebook', background='#2E2E2E')
        self.style.configure('TNotebook.Tab', background='#4A4A4A', foreground='white', padding=[10, 5])

        self.main_frame = tk.Frame(root, bg="#2E2E2E")
        self.main_frame.pack(expand=True)
        tk.Frame(self.main_frame, bg="#2E2E2E", height=10).pack()
        button_width = 25  # –æ–¥–∏–Ω–∞–∫–æ–≤–∞—è —à–∏—Ä–∏–Ω–∞
        self.load_button = ttk.Button(self.main_frame, text="–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã üìÑ", command=self.load_logs, style='Fixed.TButton', width=button_width)
        self.load_button.pack(fill='x', pady=5, padx=15)
        self.load_folder_button = ttk.Button(self.main_frame, text="–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞–ø–∫—É üìÇ", command=self.load_folder, style='Fixed.TButton', width=button_width)
        self.load_folder_button.pack(fill='x', pady=5, padx=15)
        self.merge_button = ttk.Button(self.main_frame, text="–°–æ–µ–¥–∏–Ω–∏—Ç—å –ª–æ–≥–∏ üß©", command=self.start_merge_logs, style='Fixed.TButton', width=button_width)
        self.merge_button.pack(fill='x', pady=5, padx=15)
        self.save_button = ttk.Button(self.main_frame, text="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å—ë üíæ", command=self.save_logs, state='disabled', style='Fixed.TButton', width=button_width)
        self.save_button.pack(fill='x', pady=5, padx=15)
        self.open_folder_button = ttk.Button(self.main_frame, text="–û—Ç–∫—Ä—ã—Ç—å –ø–∞–ø–∫—É üìÅ", command=self.open_folder, state='disabled', style='Fixed.TButton', width=button_width)
        self.open_folder_button.pack(fill='x', pady=5, padx=15)
        self.progress_label = tk.Label(self.main_frame, text="–ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª–æ–≥–∏", bg="#2E2E2E", fg="white", font=("Arial", 9))
        self.progress_label.pack(pady=2)
        self.animation_label = tk.Label(self.main_frame, text="", bg="#2E2E2E", fg="#00FF00", font=("Courier", 10, "bold"))
        self.animation_label.pack(pady=2)
        self.progress_bar = ttk.Progressbar(
            self.main_frame,
            orient='horizontal',
            length=200,
            mode='determinate',
            style="Green.Horizontal.TProgressbar"
        )
        self.progress_bar.pack(pady=5)
        self.animation_frames = ["|", "/", "-", "\\"]
        self.animation_index = 0
        self.is_animating = False
        self.lines_processed = 0
        self.saved_file_path = None

        self.highlight_step("load")

    def highlight_step(self, step):
        """–ü–æ–¥—Å–≤–µ—á–∏–≤–∞–µ—Ç –∫–Ω–æ–ø–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —ç—Ç–∞–ø–∞ —Ä–∞–±–æ—Ç—ã"""
        # —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—Å–µ –∫–Ω–æ–ø–∫–∏ –≤ –æ–±—ã—á–Ω—ã–π —Å—Ç–∏–ª—å
        for btn in [self.load_button, self.load_folder_button,
                    self.merge_button, self.save_button, self.open_folder_button]:
            btn.configure(style="Fixed.TButton")
        if step == "load":  # –æ–∂–∏–¥–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–æ–≤
            self.load_button.configure(style="Highlight.TButton")
            self.load_folder_button.configure(style="Highlight.TButton")
        elif step == "merge":  # –≥–æ—Ç–æ–≤—ã —Å–æ–µ–¥–∏–Ω—è—Ç—å
            self.merge_button.configure(style="Highlight.TButton")
        elif step == "save":  # –≥–æ—Ç–æ–≤—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—å
            self.save_button.configure(style="Highlight.TButton")
        elif step == "open":  # –≤—Å—ë –≥–æ—Ç–æ–≤–æ, –º–æ–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å –ø–∞–ø–∫—É
            self.open_folder_button.configure(style="Highlight.TButton")

    def update_progress(self, start_time, progress=0, bytes_processed=0, lines_processed=None):
        current_time = time.time()
        if current_time - self.last_update_time < 0.2:
            return
        with self.progress_lock:
            elapsed = time.time() - start_time
            self.progress_value = min(progress, 100)
            self.progress_bar['value'] = self.progress_value
            if bytes_processed > 0:
                mb_processed = bytes_processed / (1024 * 1024)
                self.progress_label.config(text=f"‚è± {elapsed:.1f}—Å | üì¶ {mb_processed:.1f}–ú–ë")
            elif lines_processed is not None:
                self.progress_label.config(text=f"‚è± {elapsed:.1f}—Å | üìù {lines_processed} —Å—Ç—Ä–æ–∫")
            else:
                self.progress_label.config(text=f"‚è± {elapsed:.1f}—Å")
            self.last_update_time = current_time
            try:
                self.root.update_idletasks()
            except:
                pass

    def start_animation(self):
        if not self.is_animating:
            self.is_animating = True
            self.animate()

    def animate(self):
        if self.is_animating:
            self.animation_label.config(text=f"üöÄ –†–∞–±–æ—Ç–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ {self.animation_frames[self.animation_index]}")
            self.animation_index = (self.animation_index + 1) % len(self.animation_frames)
            self.after_id = self.root.after(150, self.animate)

    def stop_animation(self):
        if self.after_id:
            self.root.after_cancel(self.after_id)
            self.after_id = None
        self.is_animating = False
        self.animation_label.config(text="")
        # –ù–µ –æ—á–∏—â–∞–µ–º progress_label –∑–¥–µ—Å—å, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

    def load_logs(self):
        files = filedialog.askopenfilenames(
            title="–í—ã–±–µ—Ä–∏—Ç–µ .log —Ñ–∞–π–ª—ã", 
            filetypes=[("Log files", "*.log *.json *.ndjson")]
        )
        if files:
            self.loaded_files.extend(list(files))
            self.progress_label.config(text=f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.loaded_files)} —Ñ–∞–π–ª–æ–≤")
        self.highlight_step("merge")

    def load_folder(self):
        folder = filedialog.askdirectory(title="–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞–ø–∫—É")
        if folder:
            log_files = []
            for root_dir, _, files in os.walk(folder):
                for file in files:
                    if file.endswith((".log", ".json", ".ndjson")):
                        log_files.append(os.path.join(root_dir, file))
            if log_files:
                self.loaded_files.extend(log_files)
                self.progress_label.config(text=f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.loaded_files)} —Ñ–∞–π–ª–æ–≤")
            else:
                self.progress_label.config(text="–ù–µ—Ç .log, .json –∏–ª–∏ .ndjson —Ñ–∞–π–ª–æ–≤")
        self.highlight_step("merge")

    def start_merge_logs(self):
        if not self.loaded_files:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã.")
            return
        self.merge_button.config(state='disabled')
        self.start_animation()
        start_time = time.time()
        threading.Thread(target=self.merge_logs_task, args=(start_time,), daemon=True).start()

    def merge_logs_task(self, start_time):
        self.temp_files = []
        self.lines_processed = 0
        total_files = len(self.loaded_files)  # –≤—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤
        try:
            with Pool(cpu_count()) as pool:
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
                args = [(i, f, self.temp_dir) for i, f in enumerate(self.loaded_files)]
                for i, temp_file in enumerate(pool.imap_unordered(process_file_and_sort_chunk, args), start=1):
                    if temp_file:
                        self.temp_files.append(temp_file)
                        # –ü–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫ –≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º —Ñ–∞–π–ª–µ
                        try:
                            with open(temp_file, 'r', encoding='utf-8') as tf:
                                lines_count = sum(1 for _ in tf)
                                self.lines_processed += lines_count
                        except Exception:
                            pass

                    # –≤—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å (% –æ—Ç —á–∏—Å–ª–∞ —Ñ–∞–π–ª–æ–≤)
                    percent = (i / total_files) * 100
                    self.root.after(
                        0,
                        lambda p=percent, lp=self.lines_processed: 
                            self.update_progress(start_time, progress=p, lines_processed=lp)
                    )
        except Exception as e:
            self.root.after(0, lambda e=e: self.handle_merge_error(e, start_time))
            return

        self.root.after(0, lambda: self.finish_merge_logs(start_time))


    def handle_merge_error(self, error, start_time):
        self.stop_animation()
        self.merge_button.config(state='normal')
        self.progress_label.config(text=f"–û—à–∏–±–∫–∞: {error}")
        self.progress_bar['value'] = 0

    def finish_merge_logs(self, start_time):
        self.stop_animation()
        elapsed = time.time() - start_time
        self.progress_label.config(text=f"‚úÖ {self.lines_processed} —Å—Ç—Ä–æ–∫ –∑–∞ {elapsed:.1f} —Å–µ–∫")
        self.progress_bar['value'] = 100
        self.merge_button.config(state='normal')
        self.save_button.config(state='normal' if self.temp_files else 'disabled')
        self.highlight_step("save")

    def save_logs(self):
        if not self.temp_files:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ —Å–æ–µ–¥–∏–Ω–∏—Ç–µ –ª–æ–≥–∏.")
            return
        self.save_button.config(state='disabled')
        self.start_animation()
        start_time = time.time()
        threading.Thread(target=self.save_final_file_thread, args=(start_time,), daemon=True).start()

    def save_final_file_thread(self, start_time):
        current_date = datetime.now().strftime("%Y-%m-%d")
        default_filename = f"mrgd({current_date}).log"
        save_path = filedialog.asksaveasfilename(
            title="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫",
            defaultextension=".log",
            initialfile=default_filename
        )
        if not save_path:
            self.root.after(0, self.stop_animation)
            self.root.after(0, lambda: self.save_button.config(state='normal'))
            return
        self.saved_file_path = save_path
        try:
            # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫
            self.total_lines = 0
            for f in self.temp_files:
                with open(f, 'r', encoding='utf-8') as temp_f:
                    self.total_lines += sum(1 for line in temp_f if line.strip())
            
            # –û—Ç–∫—Ä—ã—Ç–∏–µ –∏—Ç–µ—Ä–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –≤—Å–µ—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            iterators = []
            for f in self.temp_files:
                try:
                    it = (json.loads(line) for line in open(f, 'r', encoding='utf-8') if line.strip())
                    iterators.append(it)
                except Exception as e:
                    logging.warning(f"Cannot read temp file {f}: {e}")
            
            # –ó–∞–ø–∏—Å—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            bytes_written = 0
            with open(save_path, 'w', encoding='utf-8', errors='replace') as final_file:
                self.current_line = 0
                for entry in heapq.merge(*iterators, key=lambda x: x.get('t', '')):
                    line = json.dumps(entry, ensure_ascii=False) + '\n'
                    final_file.write(line)
                    bytes_written += len(line.encode('utf-8'))
                    self.current_line += 1
                    if self.current_line % 1000 == 0 or self.current_line == self.total_lines:
                        percent = (self.current_line / self.total_lines) * 100
                        self.root.after(0, lambda b=bytes_written, p=percent: 
                            self.update_progress(start_time, progress=p, bytes_processed=b))
            self.root.after(0, lambda: self.finish_save_logs(start_time, save_path))
        except Exception as e:
            logging.error(f"Error saving final file: {e}")
            self.root.after(0, lambda e=e: self.handle_save_error(e))

    def handle_save_error(self, error):
        self.stop_animation()
        self.save_button.config(state='normal')
        self.progress_label.config(text=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {error}")

    def finish_save_logs(self, start_time, save_path):
        self.stop_animation()
        elapsed = time.time() - start_time
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        try:
            file_size = os.path.getsize(save_path)
            mb_written = file_size / (1024 * 1024)
        except:
            mb_written = 0
        self.progress_label.config(text=f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {mb_written:.1f} –ú–ë –∑–∞ {elapsed:.1f} —Å–µ–∫")
        self.progress_bar['value'] = 100
        self.save_button.config(state='normal')
        self.open_folder_button.config(state='normal')
        self.highlight_step("open")

    def open_folder(self):
        if self.saved_file_path and os.path.exists(self.saved_file_path):
            folder_path = os.path.dirname(self.saved_file_path)
            try:
                if os.name == 'nt':  # Windows
                    os.startfile(folder_path)
                elif os.name == 'posix':  # macOS –∏–ª–∏ Linux
                    os.system(f'open "{folder_path}"' if 'darwin' in os.sys.platform else f'xdg-open "{folder_path}"')
            except Exception as e:
                messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –ø–∞–ø–∫—É: {e}")
        else:
            messagebox.showwarning("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ", "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    def __del__(self):
        try:
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception as e:
            logging.error(f"Error removing temp dir: {e}")

# Version: 031.6

if __name__ == "__main__":
    freeze_support()
    root = tk.Tk()
    app = LogMergerApp(root)
    root.mainloop()